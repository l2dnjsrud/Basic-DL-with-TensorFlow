{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07-2 linear regression(without min/max)\n",
    "\n",
    "* linear regression에 대한 설명 (Data에 대한 표준화나 정규화 없이 수행)\n",
    "\n",
    "### 기본 Library 선언 및 TensorFlow 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강의에 설명할 Data입니다\n",
    "* X Data(feature)의 값은 해당 배열의 첫번째 값부터 4번째 값까지로 정의 되고 Y Data(label)는 해당 배열의 마지막 값을 정의(5번째 값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_train = xy[:, 0:-1]\n",
    "y_train = xy[:, [-1]]\n",
    "\n",
    "plt.plot(x_train, 'ro')\n",
    "plt.plot(y_train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 Data를 기준으로 Linear Regression 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* X(features),Y(labels)는 실재 학습에 쓰일 Data (연산을 위해 Type를 맞춰준다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([3, 3],tf.zeros([3,3]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal((4, 1)), dtype=tf.float32)\n",
    "b = tf.Variable(tf.random.normal((1,)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear Regression의 Hyphthesis를 정의한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearReg_fn(features):\n",
    "    hypothesis = tf.matmul(features, W) + b\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 가설을 검증할 Cost 함수를 정의합니다(Mean Square Error를 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GradientDescentOptimizer로 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5)\n",
    "\n",
    "def grad(hypothesis, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(linearReg_fn(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b]), loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow를 통해 학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 5136834560.0000, Prediction: [[ -49687.156]\n",
      " [-100995.7  ]\n",
      " [ -79251.805]\n",
      " [ -55277.945]\n",
      " [ -65311.965]\n",
      " [ -65869.88 ]\n",
      " [ -60302.1  ]\n",
      " [ -77032.25 ]]\n",
      "Iter: 1, Loss: 5643738114795014560153600.0000, Prediction: [[1.6757712e+12]\n",
      " [3.3734994e+12]\n",
      " [2.6538103e+12]\n",
      " [1.8603067e+12]\n",
      " [2.1924710e+12]\n",
      " [2.2109246e+12]\n",
      " [2.0263888e+12]\n",
      " [2.5799961e+12]]\n",
      "Iter: 2, Loss: inf, Prediction: [[-5.5545700e+19]\n",
      " [-1.1181920e+20]\n",
      " [-8.7964132e+19]\n",
      " [-6.1662384e+19]\n",
      " [-7.2672415e+19]\n",
      " [-7.3284082e+19]\n",
      " [-6.7167397e+19]\n",
      " [-8.5517446e+19]]\n",
      "Iter: 3, Loss: inf, Prediction: [[1.8411371e+27]\n",
      " [3.7063977e+27]\n",
      " [2.9156894e+27]\n",
      " [2.0438829e+27]\n",
      " [2.4088251e+27]\n",
      " [2.4290997e+27]\n",
      " [2.2263541e+27]\n",
      " [2.8345910e+27]]\n",
      "Iter: 4, Loss: inf, Prediction: [[-6.1026973e+34]\n",
      " [-1.2285356e+35]\n",
      " [-9.6644454e+34]\n",
      " [-6.7747254e+34]\n",
      " [-7.9843760e+34]\n",
      " [-8.0515789e+34]\n",
      " [-7.3795507e+34]\n",
      " [-9.3956341e+34]]\n",
      "Iter: 5, Loss: inf, Prediction: [[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "Iter: 6, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 7, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 8, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 9, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 10, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 11, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 12, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 13, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 14, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 15, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 16, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 17, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 18, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 19, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 20, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 21, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 22, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 23, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 24, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 25, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 26, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 27, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 28, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 29, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 30, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 31, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 32, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 33, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 34, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 35, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 36, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 37, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 38, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 39, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 40, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 41, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 42, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 43, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 44, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 45, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 46, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 47, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 48, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 49, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 50, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 51, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 52, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 53, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 54, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 55, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 56, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 57, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 58, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 59, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 60, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 61, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 62, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 63, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 64, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 65, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 66, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 67, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 68, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 69, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 70, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 71, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 72, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 73, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 74, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 75, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 76, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 77, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 78, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 79, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 80, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 81, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 82, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 83, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 84, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 85, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 86, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 87, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 88, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 89, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 90, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 91, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 92, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 93, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [nan]]\n",
      "Iter: 94, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 95, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 96, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 97, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 98, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 99, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Iter: 100, Loss: nan, Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 101\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in dataset:\n",
    "        features = tf.cast(features, tf.float32)\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "        hypo_value = linearReg_fn(features)\n",
    "        grads, loss_value = grad(linearReg_fn(features), features, labels)        \n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))    \n",
    "    print(\"Iter: {}, Loss: {:.4f}, Prediction: {}\".format(step, loss_value, hypo_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
