{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 09 XOR - Logistic Regression - Eager Excuetion\n",
    "* XOR 문제를 Logistic Regression을 활용해 풀어보도록 하겠습니다.\n",
    "\n",
    "### 기본 Library 선언 및 Tensorflow 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강의에 설명할 Data입니다\n",
    "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
    "* 붉은색과 푸른색으로 0과 1을 표시해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "\n",
    "plt.scatter(x_data[0][0],x_data[0][1], c='red' , marker='^')\n",
    "plt.scatter(x_data[3][0],x_data[3][1], c='red' , marker='^')\n",
    "plt.scatter(x_data[1][0],x_data[1][1], c='blue' , marker='^')\n",
    "plt.scatter(x_data[2][0],x_data[2][1], c='blue' , marker='^')\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Eager\n",
    "### 위 Data를 기준으로 XOR처리를 위한 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* preprocess function으로 features,labels는 실재 학습에 쓰일 Data 연산을 위해 Type를 맞춰준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    features = tf.cast(features, tf.float32)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression으로 XOR모델을 만들어 보겠습니다\n",
    "### W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.]\n",
      " [0.]], B = [0.]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.zeros((2,1)), name='weight')\n",
    "b = tf.Variable(tf.zeros((1,)), name='bias')\n",
    "print(\"W = {}, B = {}\".format(W.numpy(), b.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis  = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 두수식을 합치면 아래과 같습니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientTape를 통해 경사값을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(hypothesis, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow를 통한 실행을 위해 Session를 선언합니다.\n",
    "* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6931\n",
      "Iter: 100, Loss: 0.6931\n",
      "Iter: 200, Loss: 0.6931\n",
      "Iter: 300, Loss: 0.6931\n",
      "Iter: 400, Loss: 0.6931\n",
      "Iter: 500, Loss: 0.6931\n",
      "Iter: 600, Loss: 0.6931\n",
      "Iter: 700, Loss: 0.6931\n",
      "Iter: 800, Loss: 0.6931\n",
      "Iter: 900, Loss: 0.6931\n",
      "Iter: 1000, Loss: 0.6931\n",
      "W = [[0.]\n",
      " [0.]], B = [0.]\n",
      "Testset Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in dataset:\n",
    "        features, labels = preprocess_data(features, labels)\n",
    "        grads = grad(logistic_regression(features), features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\n",
    "print(\"W = {}, B = {}\".format(W.numpy(), b.numpy()))\n",
    "x_data, y_data = preprocess_data(x_data, y_data)\n",
    "test_acc = accuracy_fn(logistic_regression(x_data),y_data)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
